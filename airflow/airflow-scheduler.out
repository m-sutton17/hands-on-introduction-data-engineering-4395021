[[34m2024-04-13 14:42:51,080[0m] {[34mscheduler_job.py:[0m714} INFO[0m - Starting the scheduler[0m
[[34m2024-04-13 14:42:51,081[0m] {[34mscheduler_job.py:[0m719} INFO[0m - Processing each file at most -1 times[0m
[[34m2024-04-13 14:42:51,082[0m] {[34mexecutor_loader.py:[0m107} INFO[0m - Loaded executor: SequentialExecutor[0m
[[34m2024-04-13 14:42:51,087[0m] {[34mmanager.py:[0m163} INFO[0m - Launched DagFileProcessorManager with pid: 19650[0m
[[34m2024-04-13 14:42:51,089[0m] {[34mscheduler_job.py:[0m1408} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2024-04-13 14:42:51,106[0m] {[34msettings.py:[0m58} INFO[0m - Configured default timezone Timezone('UTC')[0m
[2024-04-13T14:42:51.136+0000] {manager.py:409} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[[34m2024-04-13 14:43:20,060[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: challenge_dag.extract_task manual__2024-04-13T14:43:18.720369+00:00 [scheduled]>[0m
[[34m2024-04-13 14:43:20,061[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG challenge_dag has 0/16 running and queued tasks[0m
[[34m2024-04-13 14:43:20,061[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: challenge_dag.extract_task manual__2024-04-13T14:43:18.720369+00:00 [scheduled]>[0m
[[34m2024-04-13 14:43:20,063[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='challenge_dag', task_id='extract_task', run_id='manual__2024-04-13T14:43:18.720369+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-04-13 14:43:20,063[0m] {[34mbase_executor.py:[0m93} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'challenge_dag', 'extract_task', 'manual__2024-04-13T14:43:18.720369+00:00', '--local', '--subdir', 'DAGS_FOLDER/challenge_dag.py'][0m
[[34m2024-04-13 14:43:20,086[0m] {[34msequential_executor.py:[0m61} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'challenge_dag', 'extract_task', 'manual__2024-04-13T14:43:18.720369+00:00', '--local', '--subdir', 'DAGS_FOLDER/challenge_dag.py'][0m
[[34m2024-04-13 14:43:21,063[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /workspaces/hands-on-introduction-data-engineering-4395021/airflow/dags/challenge_dag.py[0m
[[34m2024-04-13 14:43:21,846[0m] {[34mtask_command.py:[0m388} INFO[0m - Running <TaskInstance: challenge_dag.extract_task manual__2024-04-13T14:43:18.720369+00:00 [queued]> on host codespaces-3318c7[0m
[[34m2024-04-13 14:43:22,831[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of challenge_dag.extract_task run_id=manual__2024-04-13T14:43:18.720369+00:00 exited with status success for try_number 1[0m
[[34m2024-04-13 14:43:22,837[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=challenge_dag, task_id=extract_task, run_id=manual__2024-04-13T14:43:18.720369+00:00, map_index=-1, run_start_date=2024-04-13 14:43:21.909204+00:00, run_end_date=2024-04-13 14:43:22.414679+00:00, run_duration=0.505475, state=success, executor_state=success, try_number=1, max_tries=0, job_id=27, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2024-04-13 14:43:20.061786+00:00, queued_by_job_id=26, pid=19868[0m
[[34m2024-04-13 14:43:22,922[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: challenge_dag.transform_task manual__2024-04-13T14:43:18.720369+00:00 [scheduled]>[0m
[[34m2024-04-13 14:43:22,922[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG challenge_dag has 0/16 running and queued tasks[0m
[[34m2024-04-13 14:43:22,922[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: challenge_dag.transform_task manual__2024-04-13T14:43:18.720369+00:00 [scheduled]>[0m
[[34m2024-04-13 14:43:22,924[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='challenge_dag', task_id='transform_task', run_id='manual__2024-04-13T14:43:18.720369+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-04-13 14:43:22,924[0m] {[34mbase_executor.py:[0m93} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'challenge_dag', 'transform_task', 'manual__2024-04-13T14:43:18.720369+00:00', '--local', '--subdir', 'DAGS_FOLDER/challenge_dag.py'][0m
[[34m2024-04-13 14:43:22,947[0m] {[34msequential_executor.py:[0m61} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'challenge_dag', 'transform_task', 'manual__2024-04-13T14:43:18.720369+00:00', '--local', '--subdir', 'DAGS_FOLDER/challenge_dag.py'][0m
[[34m2024-04-13 14:43:23,830[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /workspaces/hands-on-introduction-data-engineering-4395021/airflow/dags/challenge_dag.py[0m
[[34m2024-04-13 14:43:24,546[0m] {[34mtask_command.py:[0m388} INFO[0m - Running <TaskInstance: challenge_dag.transform_task manual__2024-04-13T14:43:18.720369+00:00 [queued]> on host codespaces-3318c7[0m
[[34m2024-04-13 14:43:25,242[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of challenge_dag.transform_task run_id=manual__2024-04-13T14:43:18.720369+00:00 exited with status success for try_number 1[0m
[[34m2024-04-13 14:43:25,246[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=challenge_dag, task_id=transform_task, run_id=manual__2024-04-13T14:43:18.720369+00:00, map_index=-1, run_start_date=2024-04-13 14:43:24.595272+00:00, run_end_date=2024-04-13 14:43:24.871540+00:00, run_duration=0.276268, state=failed, executor_state=success, try_number=1, max_tries=0, job_id=28, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-04-13 14:43:22.923286+00:00, queued_by_job_id=26, pid=19878[0m
[[34m2024-04-13 14:43:25,684[0m] {[34mdagrun.py:[0m586} ERROR[0m - Marking run <DagRun challenge_dag @ 2024-04-13 14:43:18.720369+00:00: manual__2024-04-13T14:43:18.720369+00:00, state:running, queued_at: 2024-04-13 14:43:18.750136+00:00. externally triggered: True> failed[0m
[[34m2024-04-13 14:43:25,684[0m] {[34mdagrun.py:[0m658} INFO[0m - DagRun Finished: dag_id=challenge_dag, execution_date=2024-04-13 14:43:18.720369+00:00, run_id=manual__2024-04-13T14:43:18.720369+00:00, run_start_date=2024-04-13 14:43:19.968794+00:00, run_end_date=2024-04-13 14:43:25.684726+00:00, run_duration=5.715932, state=failed, external_trigger=True, run_type=manual, data_interval_start=2024-04-13 14:43:18.720369+00:00, data_interval_end=2024-04-13 14:43:18.720369+00:00, dag_hash=fd668578d4e5b06a4875e04006565f3c[0m
[[34m2024-04-13 14:43:25,688[0m] {[34mdag.py:[0m3437} INFO[0m - Setting next_dagrun for challenge_dag to None, run_after=None[0m
[[34m2024-04-13 14:44:09,149[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: challenge_dag.extract_task manual__2024-04-13T14:44:08.039820+00:00 [scheduled]>[0m
[[34m2024-04-13 14:44:09,150[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG challenge_dag has 0/16 running and queued tasks[0m
[[34m2024-04-13 14:44:09,150[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: challenge_dag.extract_task manual__2024-04-13T14:44:08.039820+00:00 [scheduled]>[0m
[[34m2024-04-13 14:44:09,151[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='challenge_dag', task_id='extract_task', run_id='manual__2024-04-13T14:44:08.039820+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-04-13 14:44:09,151[0m] {[34mbase_executor.py:[0m93} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'challenge_dag', 'extract_task', 'manual__2024-04-13T14:44:08.039820+00:00', '--local', '--subdir', 'DAGS_FOLDER/challenge_dag.py'][0m
[[34m2024-04-13 14:44:09,176[0m] {[34msequential_executor.py:[0m61} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'challenge_dag', 'extract_task', 'manual__2024-04-13T14:44:08.039820+00:00', '--local', '--subdir', 'DAGS_FOLDER/challenge_dag.py'][0m
[[34m2024-04-13 14:44:10,405[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /workspaces/hands-on-introduction-data-engineering-4395021/airflow/dags/challenge_dag.py[0m
[[34m2024-04-13 14:44:11,137[0m] {[34mtask_command.py:[0m388} INFO[0m - Running <TaskInstance: challenge_dag.extract_task manual__2024-04-13T14:44:08.039820+00:00 [queued]> on host codespaces-3318c7[0m
[[34m2024-04-13 14:44:12,034[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of challenge_dag.extract_task run_id=manual__2024-04-13T14:44:08.039820+00:00 exited with status success for try_number 1[0m
[[34m2024-04-13 14:44:12,037[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=challenge_dag, task_id=extract_task, run_id=manual__2024-04-13T14:44:08.039820+00:00, map_index=-1, run_start_date=2024-04-13 14:44:11.190557+00:00, run_end_date=2024-04-13 14:44:11.575615+00:00, run_duration=0.385058, state=success, executor_state=success, try_number=1, max_tries=0, job_id=29, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2024-04-13 14:44:09.150809+00:00, queued_by_job_id=26, pid=20178[0m
[[34m2024-04-13 14:44:12,121[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: challenge_dag.transform_task manual__2024-04-13T14:44:08.039820+00:00 [scheduled]>[0m
[[34m2024-04-13 14:44:12,121[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG challenge_dag has 0/16 running and queued tasks[0m
[[34m2024-04-13 14:44:12,121[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: challenge_dag.transform_task manual__2024-04-13T14:44:08.039820+00:00 [scheduled]>[0m
[[34m2024-04-13 14:44:12,123[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='challenge_dag', task_id='transform_task', run_id='manual__2024-04-13T14:44:08.039820+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-04-13 14:44:12,123[0m] {[34mbase_executor.py:[0m93} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'challenge_dag', 'transform_task', 'manual__2024-04-13T14:44:08.039820+00:00', '--local', '--subdir', 'DAGS_FOLDER/challenge_dag.py'][0m
[[34m2024-04-13 14:44:12,147[0m] {[34msequential_executor.py:[0m61} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'challenge_dag', 'transform_task', 'manual__2024-04-13T14:44:08.039820+00:00', '--local', '--subdir', 'DAGS_FOLDER/challenge_dag.py'][0m
[[34m2024-04-13 14:44:13,049[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /workspaces/hands-on-introduction-data-engineering-4395021/airflow/dags/challenge_dag.py[0m
[[34m2024-04-13 14:44:13,781[0m] {[34mtask_command.py:[0m388} INFO[0m - Running <TaskInstance: challenge_dag.transform_task manual__2024-04-13T14:44:08.039820+00:00 [queued]> on host codespaces-3318c7[0m
[[34m2024-04-13 14:44:14,592[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of challenge_dag.transform_task run_id=manual__2024-04-13T14:44:08.039820+00:00 exited with status success for try_number 1[0m
[[34m2024-04-13 14:44:14,596[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=challenge_dag, task_id=transform_task, run_id=manual__2024-04-13T14:44:08.039820+00:00, map_index=-1, run_start_date=2024-04-13 14:44:13.835166+00:00, run_end_date=2024-04-13 14:44:14.139591+00:00, run_duration=0.304425, state=failed, executor_state=success, try_number=1, max_tries=0, job_id=30, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-04-13 14:44:12.122274+00:00, queued_by_job_id=26, pid=20188[0m
[[34m2024-04-13 14:44:14,623[0m] {[34mdagrun.py:[0m586} ERROR[0m - Marking run <DagRun challenge_dag @ 2024-04-13 14:44:08.039820+00:00: manual__2024-04-13T14:44:08.039820+00:00, state:running, queued_at: 2024-04-13 14:44:08.051394+00:00. externally triggered: True> failed[0m
[[34m2024-04-13 14:44:14,623[0m] {[34mdagrun.py:[0m658} INFO[0m - DagRun Finished: dag_id=challenge_dag, execution_date=2024-04-13 14:44:08.039820+00:00, run_id=manual__2024-04-13T14:44:08.039820+00:00, run_start_date=2024-04-13 14:44:09.090064+00:00, run_end_date=2024-04-13 14:44:14.623301+00:00, run_duration=5.533237, state=failed, external_trigger=True, run_type=manual, data_interval_start=2024-04-13 14:44:08.039820+00:00, data_interval_end=2024-04-13 14:44:08.039820+00:00, dag_hash=fd668578d4e5b06a4875e04006565f3c[0m
[[34m2024-04-13 14:44:14,625[0m] {[34mdag.py:[0m3437} INFO[0m - Setting next_dagrun for challenge_dag to None, run_after=None[0m
[[34m2024-04-13 14:45:49,027[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: challenge_dag.extract_task manual__2024-04-13T14:45:47.978794+00:00 [scheduled]>[0m
[[34m2024-04-13 14:45:49,027[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG challenge_dag has 0/16 running and queued tasks[0m
[[34m2024-04-13 14:45:49,028[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: challenge_dag.extract_task manual__2024-04-13T14:45:47.978794+00:00 [scheduled]>[0m
[[34m2024-04-13 14:45:49,030[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='challenge_dag', task_id='extract_task', run_id='manual__2024-04-13T14:45:47.978794+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-04-13 14:45:49,030[0m] {[34mbase_executor.py:[0m93} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'challenge_dag', 'extract_task', 'manual__2024-04-13T14:45:47.978794+00:00', '--local', '--subdir', 'DAGS_FOLDER/challenge_dag.py'][0m
[[34m2024-04-13 14:45:49,054[0m] {[34msequential_executor.py:[0m61} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'challenge_dag', 'extract_task', 'manual__2024-04-13T14:45:47.978794+00:00', '--local', '--subdir', 'DAGS_FOLDER/challenge_dag.py'][0m
[[34m2024-04-13 14:45:50,041[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /workspaces/hands-on-introduction-data-engineering-4395021/airflow/dags/challenge_dag.py[0m
[[34m2024-04-13 14:45:50,820[0m] {[34mtask_command.py:[0m388} INFO[0m - Running <TaskInstance: challenge_dag.extract_task manual__2024-04-13T14:45:47.978794+00:00 [queued]> on host codespaces-3318c7[0m
[[34m2024-04-13 14:45:51,779[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of challenge_dag.extract_task run_id=manual__2024-04-13T14:45:47.978794+00:00 exited with status success for try_number 1[0m
[[34m2024-04-13 14:45:51,782[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=challenge_dag, task_id=extract_task, run_id=manual__2024-04-13T14:45:47.978794+00:00, map_index=-1, run_start_date=2024-04-13 14:45:50.873045+00:00, run_end_date=2024-04-13 14:45:51.328420+00:00, run_duration=0.455375, state=success, executor_state=success, try_number=1, max_tries=0, job_id=31, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2024-04-13 14:45:49.028545+00:00, queued_by_job_id=26, pid=20800[0m
[[34m2024-04-13 14:45:51,865[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: challenge_dag.transform_task manual__2024-04-13T14:45:47.978794+00:00 [scheduled]>[0m
[[34m2024-04-13 14:45:51,865[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG challenge_dag has 0/16 running and queued tasks[0m
[[34m2024-04-13 14:45:51,865[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: challenge_dag.transform_task manual__2024-04-13T14:45:47.978794+00:00 [scheduled]>[0m
[[34m2024-04-13 14:45:51,870[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='challenge_dag', task_id='transform_task', run_id='manual__2024-04-13T14:45:47.978794+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-04-13 14:45:51,870[0m] {[34mbase_executor.py:[0m93} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'challenge_dag', 'transform_task', 'manual__2024-04-13T14:45:47.978794+00:00', '--local', '--subdir', 'DAGS_FOLDER/challenge_dag.py'][0m
[[34m2024-04-13 14:45:51,904[0m] {[34msequential_executor.py:[0m61} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'challenge_dag', 'transform_task', 'manual__2024-04-13T14:45:47.978794+00:00', '--local', '--subdir', 'DAGS_FOLDER/challenge_dag.py'][0m
[[34m2024-04-13 14:45:53,080[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /workspaces/hands-on-introduction-data-engineering-4395021/airflow/dags/challenge_dag.py[0m
[[34m2024-04-13 14:45:54,083[0m] {[34mtask_command.py:[0m388} INFO[0m - Running <TaskInstance: challenge_dag.transform_task manual__2024-04-13T14:45:47.978794+00:00 [queued]> on host codespaces-3318c7[0m
[[34m2024-04-13 14:45:54,841[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of challenge_dag.transform_task run_id=manual__2024-04-13T14:45:47.978794+00:00 exited with status success for try_number 1[0m
[[34m2024-04-13 14:45:54,845[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=challenge_dag, task_id=transform_task, run_id=manual__2024-04-13T14:45:47.978794+00:00, map_index=-1, run_start_date=2024-04-13 14:45:54.136789+00:00, run_end_date=2024-04-13 14:45:54.463312+00:00, run_duration=0.326523, state=success, executor_state=success, try_number=1, max_tries=0, job_id=32, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-04-13 14:45:51.866667+00:00, queued_by_job_id=26, pid=20835[0m
[[34m2024-04-13 14:45:54,919[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: challenge_dag.load_task manual__2024-04-13T14:45:47.978794+00:00 [scheduled]>[0m
[[34m2024-04-13 14:45:54,920[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG challenge_dag has 0/16 running and queued tasks[0m
[[34m2024-04-13 14:45:54,920[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: challenge_dag.load_task manual__2024-04-13T14:45:47.978794+00:00 [scheduled]>[0m
[[34m2024-04-13 14:45:54,921[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='challenge_dag', task_id='load_task', run_id='manual__2024-04-13T14:45:47.978794+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-04-13 14:45:54,922[0m] {[34mbase_executor.py:[0m93} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'challenge_dag', 'load_task', 'manual__2024-04-13T14:45:47.978794+00:00', '--local', '--subdir', 'DAGS_FOLDER/challenge_dag.py'][0m
[[34m2024-04-13 14:45:54,952[0m] {[34msequential_executor.py:[0m61} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'challenge_dag', 'load_task', 'manual__2024-04-13T14:45:47.978794+00:00', '--local', '--subdir', 'DAGS_FOLDER/challenge_dag.py'][0m
[[34m2024-04-13 14:45:55,900[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /workspaces/hands-on-introduction-data-engineering-4395021/airflow/dags/challenge_dag.py[0m
[[34m2024-04-13 14:45:56,648[0m] {[34mtask_command.py:[0m388} INFO[0m - Running <TaskInstance: challenge_dag.load_task manual__2024-04-13T14:45:47.978794+00:00 [queued]> on host codespaces-3318c7[0m
[[34m2024-04-13 14:45:57,406[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of challenge_dag.load_task run_id=manual__2024-04-13T14:45:47.978794+00:00 exited with status success for try_number 1[0m
[[34m2024-04-13 14:45:57,409[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=challenge_dag, task_id=load_task, run_id=manual__2024-04-13T14:45:47.978794+00:00, map_index=-1, run_start_date=2024-04-13 14:45:56.699728+00:00, run_end_date=2024-04-13 14:45:57.069130+00:00, run_duration=0.369402, state=success, executor_state=success, try_number=1, max_tries=0, job_id=33, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2024-04-13 14:45:54.920681+00:00, queued_by_job_id=26, pid=20850[0m
[[34m2024-04-13 14:45:57,463[0m] {[34mdagrun.py:[0m607} INFO[0m - Marking run <DagRun challenge_dag @ 2024-04-13 14:45:47.978794+00:00: manual__2024-04-13T14:45:47.978794+00:00, state:running, queued_at: 2024-04-13 14:45:47.982914+00:00. externally triggered: True> successful[0m
[[34m2024-04-13 14:45:57,464[0m] {[34mdagrun.py:[0m658} INFO[0m - DagRun Finished: dag_id=challenge_dag, execution_date=2024-04-13 14:45:47.978794+00:00, run_id=manual__2024-04-13T14:45:47.978794+00:00, run_start_date=2024-04-13 14:45:48.784026+00:00, run_end_date=2024-04-13 14:45:57.463977+00:00, run_duration=8.679951, state=success, external_trigger=True, run_type=manual, data_interval_start=2024-04-13 14:45:47.978794+00:00, data_interval_end=2024-04-13 14:45:47.978794+00:00, dag_hash=fd668578d4e5b06a4875e04006565f3c[0m
[[34m2024-04-13 14:45:57,465[0m] {[34mdag.py:[0m3437} INFO[0m - Setting next_dagrun for challenge_dag to None, run_after=None[0m
[[34m2024-04-13 14:47:51,228[0m] {[34mscheduler_job.py:[0m1408} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2024-04-13 14:52:51,445[0m] {[34mscheduler_job.py:[0m1408} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2024-04-13 14:56:09,380[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: challenge_dag.extract_task manual__2024-04-13T14:56:08.540026+00:00 [scheduled]>[0m
[[34m2024-04-13 14:56:09,380[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG challenge_dag has 0/16 running and queued tasks[0m
[[34m2024-04-13 14:56:09,380[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: challenge_dag.extract_task manual__2024-04-13T14:56:08.540026+00:00 [scheduled]>[0m
[[34m2024-04-13 14:56:09,381[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='challenge_dag', task_id='extract_task', run_id='manual__2024-04-13T14:56:08.540026+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-04-13 14:56:09,382[0m] {[34mbase_executor.py:[0m93} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'challenge_dag', 'extract_task', 'manual__2024-04-13T14:56:08.540026+00:00', '--local', '--subdir', 'DAGS_FOLDER/challenge_dag.py'][0m
[[34m2024-04-13 14:56:09,406[0m] {[34msequential_executor.py:[0m61} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'challenge_dag', 'extract_task', 'manual__2024-04-13T14:56:08.540026+00:00', '--local', '--subdir', 'DAGS_FOLDER/challenge_dag.py'][0m
[[34m2024-04-13 14:56:10,482[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /workspaces/hands-on-introduction-data-engineering-4395021/airflow/dags/challenge_dag.py[0m
[[34m2024-04-13 14:56:11,265[0m] {[34mtask_command.py:[0m388} INFO[0m - Running <TaskInstance: challenge_dag.extract_task manual__2024-04-13T14:56:08.540026+00:00 [queued]> on host codespaces-3318c7[0m
[[34m2024-04-13 14:56:12,095[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of challenge_dag.extract_task run_id=manual__2024-04-13T14:56:08.540026+00:00 exited with status success for try_number 1[0m
[[34m2024-04-13 14:56:12,099[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=challenge_dag, task_id=extract_task, run_id=manual__2024-04-13T14:56:08.540026+00:00, map_index=-1, run_start_date=2024-04-13 14:56:11.317056+00:00, run_end_date=2024-04-13 14:56:11.717474+00:00, run_duration=0.400418, state=success, executor_state=success, try_number=1, max_tries=0, job_id=34, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2024-04-13 14:56:09.380854+00:00, queued_by_job_id=26, pid=24833[0m
[[34m2024-04-13 14:56:12,179[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: challenge_dag.transform_task manual__2024-04-13T14:56:08.540026+00:00 [scheduled]>[0m
[[34m2024-04-13 14:56:12,179[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG challenge_dag has 0/16 running and queued tasks[0m
[[34m2024-04-13 14:56:12,180[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: challenge_dag.transform_task manual__2024-04-13T14:56:08.540026+00:00 [scheduled]>[0m
[[34m2024-04-13 14:56:12,181[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='challenge_dag', task_id='transform_task', run_id='manual__2024-04-13T14:56:08.540026+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-04-13 14:56:12,181[0m] {[34mbase_executor.py:[0m93} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'challenge_dag', 'transform_task', 'manual__2024-04-13T14:56:08.540026+00:00', '--local', '--subdir', 'DAGS_FOLDER/challenge_dag.py'][0m
[[34m2024-04-13 14:56:12,202[0m] {[34msequential_executor.py:[0m61} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'challenge_dag', 'transform_task', 'manual__2024-04-13T14:56:08.540026+00:00', '--local', '--subdir', 'DAGS_FOLDER/challenge_dag.py'][0m
[[34m2024-04-13 14:56:13,213[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /workspaces/hands-on-introduction-data-engineering-4395021/airflow/dags/challenge_dag.py[0m
[[34m2024-04-13 14:56:14,004[0m] {[34mtask_command.py:[0m388} INFO[0m - Running <TaskInstance: challenge_dag.transform_task manual__2024-04-13T14:56:08.540026+00:00 [queued]> on host codespaces-3318c7[0m
[[34m2024-04-13 14:56:14,795[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of challenge_dag.transform_task run_id=manual__2024-04-13T14:56:08.540026+00:00 exited with status success for try_number 1[0m
[[34m2024-04-13 14:56:14,799[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=challenge_dag, task_id=transform_task, run_id=manual__2024-04-13T14:56:08.540026+00:00, map_index=-1, run_start_date=2024-04-13 14:56:14.055526+00:00, run_end_date=2024-04-13 14:56:14.353606+00:00, run_duration=0.29808, state=failed, executor_state=success, try_number=1, max_tries=0, job_id=35, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-04-13 14:56:12.180436+00:00, queued_by_job_id=26, pid=24872[0m
[[34m2024-04-13 14:56:14,826[0m] {[34mdagrun.py:[0m586} ERROR[0m - Marking run <DagRun challenge_dag @ 2024-04-13 14:56:08.540026+00:00: manual__2024-04-13T14:56:08.540026+00:00, state:running, queued_at: 2024-04-13 14:56:08.549907+00:00. externally triggered: True> failed[0m
[[34m2024-04-13 14:56:14,827[0m] {[34mdagrun.py:[0m658} INFO[0m - DagRun Finished: dag_id=challenge_dag, execution_date=2024-04-13 14:56:08.540026+00:00, run_id=manual__2024-04-13T14:56:08.540026+00:00, run_start_date=2024-04-13 14:56:09.230132+00:00, run_end_date=2024-04-13 14:56:14.827145+00:00, run_duration=5.597013, state=failed, external_trigger=True, run_type=manual, data_interval_start=2024-04-13 14:56:08.540026+00:00, data_interval_end=2024-04-13 14:56:08.540026+00:00, dag_hash=fd668578d4e5b06a4875e04006565f3c[0m
[[34m2024-04-13 14:56:14,829[0m] {[34mdag.py:[0m3437} INFO[0m - Setting next_dagrun for challenge_dag to None, run_after=None[0m
[[34m2024-04-13 14:56:52,467[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: challenge_dag.extract_task manual__2024-04-13T14:56:51.327899+00:00 [scheduled]>[0m
[[34m2024-04-13 14:56:52,467[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG challenge_dag has 0/16 running and queued tasks[0m
[[34m2024-04-13 14:56:52,467[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: challenge_dag.extract_task manual__2024-04-13T14:56:51.327899+00:00 [scheduled]>[0m
[[34m2024-04-13 14:56:52,469[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='challenge_dag', task_id='extract_task', run_id='manual__2024-04-13T14:56:51.327899+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-04-13 14:56:52,469[0m] {[34mbase_executor.py:[0m93} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'challenge_dag', 'extract_task', 'manual__2024-04-13T14:56:51.327899+00:00', '--local', '--subdir', 'DAGS_FOLDER/challenge_dag.py'][0m
[[34m2024-04-13 14:56:52,491[0m] {[34msequential_executor.py:[0m61} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'challenge_dag', 'extract_task', 'manual__2024-04-13T14:56:51.327899+00:00', '--local', '--subdir', 'DAGS_FOLDER/challenge_dag.py'][0m
[[34m2024-04-13 14:56:53,502[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /workspaces/hands-on-introduction-data-engineering-4395021/airflow/dags/challenge_dag.py[0m
[[34m2024-04-13 14:56:54,332[0m] {[34mtask_command.py:[0m388} INFO[0m - Running <TaskInstance: challenge_dag.extract_task manual__2024-04-13T14:56:51.327899+00:00 [queued]> on host codespaces-3318c7[0m
[[34m2024-04-13 14:56:55,165[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of challenge_dag.extract_task run_id=manual__2024-04-13T14:56:51.327899+00:00 exited with status success for try_number 1[0m
[[34m2024-04-13 14:56:55,169[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=challenge_dag, task_id=extract_task, run_id=manual__2024-04-13T14:56:51.327899+00:00, map_index=-1, run_start_date=2024-04-13 14:56:54.385318+00:00, run_end_date=2024-04-13 14:56:54.759782+00:00, run_duration=0.374464, state=success, executor_state=success, try_number=1, max_tries=0, job_id=36, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2024-04-13 14:56:52.468364+00:00, queued_by_job_id=26, pid=25128[0m
[[34m2024-04-13 14:56:55,251[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: challenge_dag.transform_task manual__2024-04-13T14:56:51.327899+00:00 [scheduled]>[0m
[[34m2024-04-13 14:56:55,251[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG challenge_dag has 0/16 running and queued tasks[0m
[[34m2024-04-13 14:56:55,251[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: challenge_dag.transform_task manual__2024-04-13T14:56:51.327899+00:00 [scheduled]>[0m
[[34m2024-04-13 14:56:55,252[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='challenge_dag', task_id='transform_task', run_id='manual__2024-04-13T14:56:51.327899+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-04-13 14:56:55,253[0m] {[34mbase_executor.py:[0m93} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'challenge_dag', 'transform_task', 'manual__2024-04-13T14:56:51.327899+00:00', '--local', '--subdir', 'DAGS_FOLDER/challenge_dag.py'][0m
[[34m2024-04-13 14:56:55,286[0m] {[34msequential_executor.py:[0m61} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'challenge_dag', 'transform_task', 'manual__2024-04-13T14:56:51.327899+00:00', '--local', '--subdir', 'DAGS_FOLDER/challenge_dag.py'][0m
[[34m2024-04-13 14:56:56,207[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /workspaces/hands-on-introduction-data-engineering-4395021/airflow/dags/challenge_dag.py[0m
[[34m2024-04-13 14:56:57,014[0m] {[34mtask_command.py:[0m388} INFO[0m - Running <TaskInstance: challenge_dag.transform_task manual__2024-04-13T14:56:51.327899+00:00 [queued]> on host codespaces-3318c7[0m
[[34m2024-04-13 14:56:57,747[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of challenge_dag.transform_task run_id=manual__2024-04-13T14:56:51.327899+00:00 exited with status success for try_number 1[0m
[[34m2024-04-13 14:56:57,750[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=challenge_dag, task_id=transform_task, run_id=manual__2024-04-13T14:56:51.327899+00:00, map_index=-1, run_start_date=2024-04-13 14:56:57.065007+00:00, run_end_date=2024-04-13 14:56:57.331287+00:00, run_duration=0.26628, state=failed, executor_state=success, try_number=1, max_tries=0, job_id=37, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-04-13 14:56:55.251860+00:00, queued_by_job_id=26, pid=25144[0m
[[34m2024-04-13 14:56:57,883[0m] {[34mdagrun.py:[0m586} ERROR[0m - Marking run <DagRun challenge_dag @ 2024-04-13 14:56:51.327899+00:00: manual__2024-04-13T14:56:51.327899+00:00, state:running, queued_at: 2024-04-13 14:56:51.335274+00:00. externally triggered: True> failed[0m
[[34m2024-04-13 14:56:57,883[0m] {[34mdagrun.py:[0m658} INFO[0m - DagRun Finished: dag_id=challenge_dag, execution_date=2024-04-13 14:56:51.327899+00:00, run_id=manual__2024-04-13T14:56:51.327899+00:00, run_start_date=2024-04-13 14:56:52.411764+00:00, run_end_date=2024-04-13 14:56:57.883714+00:00, run_duration=5.47195, state=failed, external_trigger=True, run_type=manual, data_interval_start=2024-04-13 14:56:51.327899+00:00, data_interval_end=2024-04-13 14:56:51.327899+00:00, dag_hash=fd668578d4e5b06a4875e04006565f3c[0m
[[34m2024-04-13 14:56:57,885[0m] {[34mdag.py:[0m3437} INFO[0m - Setting next_dagrun for challenge_dag to None, run_after=None[0m
[[34m2024-04-13 14:57:51,789[0m] {[34mscheduler_job.py:[0m1408} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2024-04-13 14:58:08,428[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: challenge_dag.extract_task manual__2024-04-13T14:58:07.963940+00:00 [scheduled]>[0m
[[34m2024-04-13 14:58:08,429[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG challenge_dag has 0/16 running and queued tasks[0m
[[34m2024-04-13 14:58:08,429[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: challenge_dag.extract_task manual__2024-04-13T14:58:07.963940+00:00 [scheduled]>[0m
[[34m2024-04-13 14:58:08,486[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='challenge_dag', task_id='extract_task', run_id='manual__2024-04-13T14:58:07.963940+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-04-13 14:58:08,487[0m] {[34mbase_executor.py:[0m93} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'challenge_dag', 'extract_task', 'manual__2024-04-13T14:58:07.963940+00:00', '--local', '--subdir', 'DAGS_FOLDER/challenge_dag.py'][0m
[[34m2024-04-13 14:58:08,513[0m] {[34msequential_executor.py:[0m61} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'challenge_dag', 'extract_task', 'manual__2024-04-13T14:58:07.963940+00:00', '--local', '--subdir', 'DAGS_FOLDER/challenge_dag.py'][0m
[[34m2024-04-13 14:58:09,680[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /workspaces/hands-on-introduction-data-engineering-4395021/airflow/dags/challenge_dag.py[0m
[[34m2024-04-13 14:58:10,465[0m] {[34mtask_command.py:[0m388} INFO[0m - Running <TaskInstance: challenge_dag.extract_task manual__2024-04-13T14:58:07.963940+00:00 [queued]> on host codespaces-3318c7[0m
[[34m2024-04-13 14:58:11,412[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of challenge_dag.extract_task run_id=manual__2024-04-13T14:58:07.963940+00:00 exited with status success for try_number 1[0m
[[34m2024-04-13 14:58:11,415[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=challenge_dag, task_id=extract_task, run_id=manual__2024-04-13T14:58:07.963940+00:00, map_index=-1, run_start_date=2024-04-13 14:58:10.515304+00:00, run_end_date=2024-04-13 14:58:10.900093+00:00, run_duration=0.384789, state=success, executor_state=success, try_number=1, max_tries=0, job_id=38, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2024-04-13 14:58:08.431982+00:00, queued_by_job_id=26, pid=25601[0m
[[34m2024-04-13 14:58:11,471[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: challenge_dag.transform_task manual__2024-04-13T14:58:07.963940+00:00 [scheduled]>[0m
[[34m2024-04-13 14:58:11,471[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG challenge_dag has 0/16 running and queued tasks[0m
[[34m2024-04-13 14:58:11,471[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: challenge_dag.transform_task manual__2024-04-13T14:58:07.963940+00:00 [scheduled]>[0m
[[34m2024-04-13 14:58:11,473[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='challenge_dag', task_id='transform_task', run_id='manual__2024-04-13T14:58:07.963940+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-04-13 14:58:11,473[0m] {[34mbase_executor.py:[0m93} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'challenge_dag', 'transform_task', 'manual__2024-04-13T14:58:07.963940+00:00', '--local', '--subdir', 'DAGS_FOLDER/challenge_dag.py'][0m
[[34m2024-04-13 14:58:11,495[0m] {[34msequential_executor.py:[0m61} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'challenge_dag', 'transform_task', 'manual__2024-04-13T14:58:07.963940+00:00', '--local', '--subdir', 'DAGS_FOLDER/challenge_dag.py'][0m
[[34m2024-04-13 14:58:12,366[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /workspaces/hands-on-introduction-data-engineering-4395021/airflow/dags/challenge_dag.py[0m
[[34m2024-04-13 14:58:13,230[0m] {[34mtask_command.py:[0m388} INFO[0m - Running <TaskInstance: challenge_dag.transform_task manual__2024-04-13T14:58:07.963940+00:00 [queued]> on host codespaces-3318c7[0m
[[34m2024-04-13 14:58:13,967[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of challenge_dag.transform_task run_id=manual__2024-04-13T14:58:07.963940+00:00 exited with status success for try_number 1[0m
[[34m2024-04-13 14:58:13,971[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=challenge_dag, task_id=transform_task, run_id=manual__2024-04-13T14:58:07.963940+00:00, map_index=-1, run_start_date=2024-04-13 14:58:13.295189+00:00, run_end_date=2024-04-13 14:58:13.554546+00:00, run_duration=0.259357, state=failed, executor_state=success, try_number=1, max_tries=0, job_id=39, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-04-13 14:58:11.472082+00:00, queued_by_job_id=26, pid=25627[0m
[[34m2024-04-13 14:58:14,027[0m] {[34mdagrun.py:[0m586} ERROR[0m - Marking run <DagRun challenge_dag @ 2024-04-13 14:58:07.963940+00:00: manual__2024-04-13T14:58:07.963940+00:00, state:running, queued_at: 2024-04-13 14:58:07.968439+00:00. externally triggered: True> failed[0m
[[34m2024-04-13 14:58:14,028[0m] {[34mdagrun.py:[0m658} INFO[0m - DagRun Finished: dag_id=challenge_dag, execution_date=2024-04-13 14:58:07.963940+00:00, run_id=manual__2024-04-13T14:58:07.963940+00:00, run_start_date=2024-04-13 14:58:08.232495+00:00, run_end_date=2024-04-13 14:58:14.028084+00:00, run_duration=5.795589, state=failed, external_trigger=True, run_type=manual, data_interval_start=2024-04-13 14:58:07.963940+00:00, data_interval_end=2024-04-13 14:58:07.963940+00:00, dag_hash=fd668578d4e5b06a4875e04006565f3c[0m
[[34m2024-04-13 14:58:14,030[0m] {[34mdag.py:[0m3437} INFO[0m - Setting next_dagrun for challenge_dag to None, run_after=None[0m
[[34m2024-04-13 15:02:51,828[0m] {[34mscheduler_job.py:[0m1408} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2024-04-13 15:05:52,727[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: challenge_dag.extract_task manual__2024-04-13T15:05:51.926021+00:00 [scheduled]>[0m
[[34m2024-04-13 15:05:52,727[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG challenge_dag has 0/16 running and queued tasks[0m
[[34m2024-04-13 15:05:52,727[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: challenge_dag.extract_task manual__2024-04-13T15:05:51.926021+00:00 [scheduled]>[0m
[[34m2024-04-13 15:05:52,808[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='challenge_dag', task_id='extract_task', run_id='manual__2024-04-13T15:05:51.926021+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-04-13 15:05:52,808[0m] {[34mbase_executor.py:[0m93} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'challenge_dag', 'extract_task', 'manual__2024-04-13T15:05:51.926021+00:00', '--local', '--subdir', 'DAGS_FOLDER/challenge_dag.py'][0m
[[34m2024-04-13 15:05:52,831[0m] {[34msequential_executor.py:[0m61} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'challenge_dag', 'extract_task', 'manual__2024-04-13T15:05:51.926021+00:00', '--local', '--subdir', 'DAGS_FOLDER/challenge_dag.py'][0m
[[34m2024-04-13 15:05:53,986[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /workspaces/hands-on-introduction-data-engineering-4395021/airflow/dags/challenge_dag.py[0m
[[34m2024-04-13 15:05:54,808[0m] {[34mtask_command.py:[0m388} INFO[0m - Running <TaskInstance: challenge_dag.extract_task manual__2024-04-13T15:05:51.926021+00:00 [queued]> on host codespaces-3318c7[0m
[[34m2024-04-13 15:05:55,664[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of challenge_dag.extract_task run_id=manual__2024-04-13T15:05:51.926021+00:00 exited with status success for try_number 1[0m
[[34m2024-04-13 15:05:55,667[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=challenge_dag, task_id=extract_task, run_id=manual__2024-04-13T15:05:51.926021+00:00, map_index=-1, run_start_date=2024-04-13 15:05:54.868571+00:00, run_end_date=2024-04-13 15:05:55.256494+00:00, run_duration=0.387923, state=success, executor_state=success, try_number=1, max_tries=0, job_id=40, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2024-04-13 15:05:52.728146+00:00, queued_by_job_id=26, pid=28566[0m
[[34m2024-04-13 15:05:55,751[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: challenge_dag.transform_task manual__2024-04-13T15:05:51.926021+00:00 [scheduled]>[0m
[[34m2024-04-13 15:05:55,752[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG challenge_dag has 0/16 running and queued tasks[0m
[[34m2024-04-13 15:05:55,752[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: challenge_dag.transform_task manual__2024-04-13T15:05:51.926021+00:00 [scheduled]>[0m
[[34m2024-04-13 15:05:55,753[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='challenge_dag', task_id='transform_task', run_id='manual__2024-04-13T15:05:51.926021+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-04-13 15:05:55,753[0m] {[34mbase_executor.py:[0m93} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'challenge_dag', 'transform_task', 'manual__2024-04-13T15:05:51.926021+00:00', '--local', '--subdir', 'DAGS_FOLDER/challenge_dag.py'][0m
[[34m2024-04-13 15:05:55,776[0m] {[34msequential_executor.py:[0m61} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'challenge_dag', 'transform_task', 'manual__2024-04-13T15:05:51.926021+00:00', '--local', '--subdir', 'DAGS_FOLDER/challenge_dag.py'][0m
[[34m2024-04-13 15:05:56,664[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /workspaces/hands-on-introduction-data-engineering-4395021/airflow/dags/challenge_dag.py[0m
[[34m2024-04-13 15:05:57,394[0m] {[34mtask_command.py:[0m388} INFO[0m - Running <TaskInstance: challenge_dag.transform_task manual__2024-04-13T15:05:51.926021+00:00 [queued]> on host codespaces-3318c7[0m
[[34m2024-04-13 15:05:58,137[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of challenge_dag.transform_task run_id=manual__2024-04-13T15:05:51.926021+00:00 exited with status success for try_number 1[0m
[[34m2024-04-13 15:05:58,140[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=challenge_dag, task_id=transform_task, run_id=manual__2024-04-13T15:05:51.926021+00:00, map_index=-1, run_start_date=2024-04-13 15:05:57.444320+00:00, run_end_date=2024-04-13 15:05:57.711899+00:00, run_duration=0.267579, state=success, executor_state=success, try_number=1, max_tries=0, job_id=41, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-04-13 15:05:55.752700+00:00, queued_by_job_id=26, pid=28576[0m
[[34m2024-04-13 15:05:58,509[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: challenge_dag.load_task manual__2024-04-13T15:05:51.926021+00:00 [scheduled]>[0m
[[34m2024-04-13 15:05:58,509[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG challenge_dag has 0/16 running and queued tasks[0m
[[34m2024-04-13 15:05:58,509[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: challenge_dag.load_task manual__2024-04-13T15:05:51.926021+00:00 [scheduled]>[0m
[[34m2024-04-13 15:05:58,510[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='challenge_dag', task_id='load_task', run_id='manual__2024-04-13T15:05:51.926021+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-04-13 15:05:58,511[0m] {[34mbase_executor.py:[0m93} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'challenge_dag', 'load_task', 'manual__2024-04-13T15:05:51.926021+00:00', '--local', '--subdir', 'DAGS_FOLDER/challenge_dag.py'][0m
[[34m2024-04-13 15:05:58,535[0m] {[34msequential_executor.py:[0m61} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'challenge_dag', 'load_task', 'manual__2024-04-13T15:05:51.926021+00:00', '--local', '--subdir', 'DAGS_FOLDER/challenge_dag.py'][0m
[[34m2024-04-13 15:05:59,557[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /workspaces/hands-on-introduction-data-engineering-4395021/airflow/dags/challenge_dag.py[0m
[[34m2024-04-13 15:06:00,397[0m] {[34mtask_command.py:[0m388} INFO[0m - Running <TaskInstance: challenge_dag.load_task manual__2024-04-13T15:05:51.926021+00:00 [queued]> on host codespaces-3318c7[0m
[[34m2024-04-13 15:06:01,156[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of challenge_dag.load_task run_id=manual__2024-04-13T15:05:51.926021+00:00 exited with status success for try_number 1[0m
[[34m2024-04-13 15:06:01,159[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=challenge_dag, task_id=load_task, run_id=manual__2024-04-13T15:05:51.926021+00:00, map_index=-1, run_start_date=2024-04-13 15:06:00.451605+00:00, run_end_date=2024-04-13 15:06:00.783467+00:00, run_duration=0.331862, state=success, executor_state=success, try_number=1, max_tries=0, job_id=42, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2024-04-13 15:05:58.509956+00:00, queued_by_job_id=26, pid=28592[0m
[[34m2024-04-13 15:06:01,319[0m] {[34mdagrun.py:[0m607} INFO[0m - Marking run <DagRun challenge_dag @ 2024-04-13 15:05:51.926021+00:00: manual__2024-04-13T15:05:51.926021+00:00, state:running, queued_at: 2024-04-13 15:05:51.930110+00:00. externally triggered: True> successful[0m
[[34m2024-04-13 15:06:01,319[0m] {[34mdagrun.py:[0m658} INFO[0m - DagRun Finished: dag_id=challenge_dag, execution_date=2024-04-13 15:05:51.926021+00:00, run_id=manual__2024-04-13T15:05:51.926021+00:00, run_start_date=2024-04-13 15:05:52.603216+00:00, run_end_date=2024-04-13 15:06:01.319673+00:00, run_duration=8.716457, state=success, external_trigger=True, run_type=manual, data_interval_start=2024-04-13 15:05:51.926021+00:00, data_interval_end=2024-04-13 15:05:51.926021+00:00, dag_hash=fd668578d4e5b06a4875e04006565f3c[0m
[[34m2024-04-13 15:06:01,321[0m] {[34mdag.py:[0m3437} INFO[0m - Setting next_dagrun for challenge_dag to None, run_after=None[0m
[[34m2024-04-13 15:07:51,858[0m] {[34mscheduler_job.py:[0m1408} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2024-04-13 15:12:51,887[0m] {[34mscheduler_job.py:[0m1408} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2024-04-13 15:17:51,915[0m] {[34mscheduler_job.py:[0m1408} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2024-04-13 15:21:46,093[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: challenge_dag.extract_task manual__2024-04-13T15:21:44.130792+00:00 [scheduled]>[0m
[[34m2024-04-13 15:21:46,093[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG challenge_dag has 0/16 running and queued tasks[0m
[[34m2024-04-13 15:21:46,093[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: challenge_dag.extract_task manual__2024-04-13T15:21:44.130792+00:00 [scheduled]>[0m
[[34m2024-04-13 15:21:46,094[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='challenge_dag', task_id='extract_task', run_id='manual__2024-04-13T15:21:44.130792+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-04-13 15:21:46,095[0m] {[34mbase_executor.py:[0m93} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'challenge_dag', 'extract_task', 'manual__2024-04-13T15:21:44.130792+00:00', '--local', '--subdir', 'DAGS_FOLDER/challenge_dag.py'][0m
[[34m2024-04-13 15:21:46,118[0m] {[34msequential_executor.py:[0m61} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'challenge_dag', 'extract_task', 'manual__2024-04-13T15:21:44.130792+00:00', '--local', '--subdir', 'DAGS_FOLDER/challenge_dag.py'][0m
[[34m2024-04-13 15:21:47,000[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /workspaces/hands-on-introduction-data-engineering-4395021/airflow/dags/challenge_dag.py[0m
[[34m2024-04-13 15:21:47,936[0m] {[34mtask_command.py:[0m388} INFO[0m - Running <TaskInstance: challenge_dag.extract_task manual__2024-04-13T15:21:44.130792+00:00 [queued]> on host codespaces-3318c7[0m
[[34m2024-04-13 15:21:48,964[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of challenge_dag.extract_task run_id=manual__2024-04-13T15:21:44.130792+00:00 exited with status success for try_number 1[0m
[[34m2024-04-13 15:21:48,968[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=challenge_dag, task_id=extract_task, run_id=manual__2024-04-13T15:21:44.130792+00:00, map_index=-1, run_start_date=2024-04-13 15:21:47.985582+00:00, run_end_date=2024-04-13 15:21:48.382507+00:00, run_duration=0.396925, state=success, executor_state=success, try_number=1, max_tries=0, job_id=43, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2024-04-13 15:21:46.093895+00:00, queued_by_job_id=26, pid=34655[0m
[[34m2024-04-13 15:21:49,022[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: challenge_dag.transform_task manual__2024-04-13T15:21:44.130792+00:00 [scheduled]>[0m
[[34m2024-04-13 15:21:49,022[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG challenge_dag has 0/16 running and queued tasks[0m
[[34m2024-04-13 15:21:49,022[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: challenge_dag.transform_task manual__2024-04-13T15:21:44.130792+00:00 [scheduled]>[0m
[[34m2024-04-13 15:21:49,024[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='challenge_dag', task_id='transform_task', run_id='manual__2024-04-13T15:21:44.130792+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-04-13 15:21:49,024[0m] {[34mbase_executor.py:[0m93} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'challenge_dag', 'transform_task', 'manual__2024-04-13T15:21:44.130792+00:00', '--local', '--subdir', 'DAGS_FOLDER/challenge_dag.py'][0m
[[34m2024-04-13 15:21:49,044[0m] {[34msequential_executor.py:[0m61} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'challenge_dag', 'transform_task', 'manual__2024-04-13T15:21:44.130792+00:00', '--local', '--subdir', 'DAGS_FOLDER/challenge_dag.py'][0m
[[34m2024-04-13 15:21:50,106[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /workspaces/hands-on-introduction-data-engineering-4395021/airflow/dags/challenge_dag.py[0m
[[34m2024-04-13 15:21:50,869[0m] {[34mtask_command.py:[0m388} INFO[0m - Running <TaskInstance: challenge_dag.transform_task manual__2024-04-13T15:21:44.130792+00:00 [queued]> on host codespaces-3318c7[0m
[[34m2024-04-13 15:21:51,638[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of challenge_dag.transform_task run_id=manual__2024-04-13T15:21:44.130792+00:00 exited with status success for try_number 1[0m
[[34m2024-04-13 15:21:51,642[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=challenge_dag, task_id=transform_task, run_id=manual__2024-04-13T15:21:44.130792+00:00, map_index=-1, run_start_date=2024-04-13 15:21:50.931710+00:00, run_end_date=2024-04-13 15:21:51.194171+00:00, run_duration=0.262461, state=success, executor_state=success, try_number=1, max_tries=0, job_id=44, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-04-13 15:21:49.022949+00:00, queued_by_job_id=26, pid=34694[0m
[[34m2024-04-13 15:21:52,084[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: challenge_dag.load_task manual__2024-04-13T15:21:44.130792+00:00 [scheduled]>[0m
[[34m2024-04-13 15:21:52,085[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG challenge_dag has 0/16 running and queued tasks[0m
[[34m2024-04-13 15:21:52,085[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: challenge_dag.load_task manual__2024-04-13T15:21:44.130792+00:00 [scheduled]>[0m
[[34m2024-04-13 15:21:52,086[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='challenge_dag', task_id='load_task', run_id='manual__2024-04-13T15:21:44.130792+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-04-13 15:21:52,086[0m] {[34mbase_executor.py:[0m93} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'challenge_dag', 'load_task', 'manual__2024-04-13T15:21:44.130792+00:00', '--local', '--subdir', 'DAGS_FOLDER/challenge_dag.py'][0m
[[34m2024-04-13 15:21:52,110[0m] {[34msequential_executor.py:[0m61} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'challenge_dag', 'load_task', 'manual__2024-04-13T15:21:44.130792+00:00', '--local', '--subdir', 'DAGS_FOLDER/challenge_dag.py'][0m
[[34m2024-04-13 15:21:53,070[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /workspaces/hands-on-introduction-data-engineering-4395021/airflow/dags/challenge_dag.py[0m
[[34m2024-04-13 15:21:53,796[0m] {[34mtask_command.py:[0m388} INFO[0m - Running <TaskInstance: challenge_dag.load_task manual__2024-04-13T15:21:44.130792+00:00 [queued]> on host codespaces-3318c7[0m
[[34m2024-04-13 15:21:54,532[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of challenge_dag.load_task run_id=manual__2024-04-13T15:21:44.130792+00:00 exited with status success for try_number 1[0m
[[34m2024-04-13 15:21:54,536[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=challenge_dag, task_id=load_task, run_id=manual__2024-04-13T15:21:44.130792+00:00, map_index=-1, run_start_date=2024-04-13 15:21:53.854442+00:00, run_end_date=2024-04-13 15:21:54.169135+00:00, run_duration=0.314693, state=success, executor_state=success, try_number=1, max_tries=0, job_id=45, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2024-04-13 15:21:52.085760+00:00, queued_by_job_id=26, pid=34704[0m
[[34m2024-04-13 15:21:54,667[0m] {[34mdagrun.py:[0m607} INFO[0m - Marking run <DagRun challenge_dag @ 2024-04-13 15:21:44.130792+00:00: manual__2024-04-13T15:21:44.130792+00:00, state:running, queued_at: 2024-04-13 15:21:44.136381+00:00. externally triggered: True> successful[0m
[[34m2024-04-13 15:21:54,667[0m] {[34mdagrun.py:[0m658} INFO[0m - DagRun Finished: dag_id=challenge_dag, execution_date=2024-04-13 15:21:44.130792+00:00, run_id=manual__2024-04-13T15:21:44.130792+00:00, run_start_date=2024-04-13 15:21:46.033544+00:00, run_end_date=2024-04-13 15:21:54.667924+00:00, run_duration=8.63438, state=success, external_trigger=True, run_type=manual, data_interval_start=2024-04-13 15:21:44.130792+00:00, data_interval_end=2024-04-13 15:21:44.130792+00:00, dag_hash=b029ce7f4b6d12b9dd45aea6512fdff3[0m
[[34m2024-04-13 15:21:54,669[0m] {[34mdag.py:[0m3437} INFO[0m - Setting next_dagrun for challenge_dag to None, run_after=None[0m
[[34m2024-04-13 15:22:51,941[0m] {[34mscheduler_job.py:[0m1408} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2024-04-13 15:27:51,969[0m] {[34mscheduler_job.py:[0m1408} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2024-04-13 15:32:51,996[0m] {[34mscheduler_job.py:[0m1408} INFO[0m - Resetting orphaned tasks for active dag runs[0m
